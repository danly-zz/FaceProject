optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.001,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}


dataset : {
  train : {NAME: NAME, 
  DATA_PATH : ./datasets/pretrain, 
  PC_PATH : /path/to/pointclouds,
  subset : 'train',
  bs : 32},

  val : {NAME: NAME,
  DATA_PATH : ./datasets/pretrain,
  PC_PATH : /path/to/pointclouds,
  subset : 'val',
  bs : 32},

  test : {NAME: NAME,
  DATA_PATH : ./datasets/pretrain,
  N_POINTS : 32251,
  PC_PATH : /path/to/pointclouds,
  subset : 'test',
  bs : 32}}

model : {
  NAME: Point_MAE,
  group_size: 192,
  num_group: 256,
  loss: cdl2,
  transformer_config: {
    mask_ratio: 0.6,
    mask_type: 'rand',
    trans_dim: 384,
    encoder_dims: 384,
    depth: 12,
    drop_path_rate: 0.1,
    num_heads: 6,
    decoder_depth: 4,
    decoder_num_heads: 6,
  },
  }

npoints: 32251
total_bs : 32
step_per_update : 1
max_epoch : 300
model_dir : "./"
model_name: pretrain.pth