{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.logger import *\n",
    "\n",
    "\n",
    "## 设置GPU可见设备\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 检查当前选择的 GPU\n",
    "print(\"Current device index:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb091ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_dataloader, val_dataloader, model, optimizer, scheduler, config, device):\n",
    "    start_epoch = 1\n",
    "\n",
    "    best_loss = 1e10\n",
    "    train_loss_array = np.array([])\n",
    "    val_loss_array = np.array([])\n",
    "\n",
    "    best_model = None\n",
    "    best_model_path = os.path.join(config.model_dir, config.model_name)\n",
    "\n",
    "    model.zero_grad()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(start_epoch,config.max_epoch+1):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        epoch_start_time = time.time()\n",
    "        num_iter = 0\n",
    "\n",
    "        for idx, (_,data, _, age, _) in enumerate(train_dataloader):\n",
    "            batch_start_time = time.time()\n",
    "            num_iter += 1\n",
    "            \n",
    "            points = data.to(device)\n",
    "            label = age.to(device).float()\n",
    "            \n",
    "            ret = model(points)\n",
    "            loss = model.module.get_loss_acc(ret, label,config.model.loss)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # forward\n",
    "            if num_iter == config.step_per_update:\n",
    "                if config.get('grad_norm_clip') is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip, norm_type=2)\n",
    "                num_iter = 0\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            running_train_loss += batch_loss\n",
    "            batch_duration = time.time() - batch_start_time\n",
    "\n",
    "            wandb.log({\n",
    "                \"batch_duration\": batch_duration,\n",
    "                \"batch_train_loss\": batch_loss,\n",
    "            })\n",
    "        if isinstance(scheduler, list):\n",
    "            for item in scheduler:\n",
    "                item.step(epoch)\n",
    "        else:\n",
    "            scheduler.step(epoch)\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader)\n",
    "        \n",
    "\n",
    "        ## 评估模型在验证集上的表现\n",
    "        val_start_time = time.time()\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for idx, (_,data, _,age, _) in enumerate(val_dataloader):\n",
    "                points = data.to(device)\n",
    "                label = age.to(device).float()\n",
    "                ret = model(points)\n",
    "                loss = model.module.get_loss_acc(ret, label,config.model.loss)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "        \n",
    "        train_loss_array = np.append(train_loss_array, epoch_train_loss)\n",
    "        val_loss_array = np.append(val_loss_array, epoch_val_loss)\n",
    "        val_duration = time.time() - val_start_time\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\":epoch,\n",
    "            \"val_duration\": val_duration,\n",
    "            \"epoch_train_loss\": epoch_train_loss,\n",
    "            \"epoch_val_loss\": epoch_val_loss,\n",
    "            \"epoch_duration\": epoch_duration\n",
    "        })\n",
    "        print(f\"Epoch {epoch}/{config.max_epoch} finished. Train Average Loss: {epoch_train_loss:.4f}, Validation Average Loss :{epoch_val_loss:.4f}, Duration: {epoch_duration:.2f}s\")\n",
    "        if epoch_val_loss < best_loss:\n",
    "            best_loss = epoch_val_loss\n",
    "            best_model = model.module.state_dict()\n",
    "            torch.save(best_model, best_model_path)\n",
    "            print('Save the best model to %s' % best_model_path) \n",
    "     \n",
    "    return train_loss_array, val_loss_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6c6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lidan/miniconda3/envs/pointmae_py39/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## 训练模型 \n",
    "import yaml\n",
    "import pickle\n",
    "from easydict import EasyDict as edict\n",
    "from models.Point_MAE import PointTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a395f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取配置文件\n",
    "with open('finetune_age.yaml', 'r') as f:\n",
    "    config = edict(yaml.safe_load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import misc\n",
    "from datasets.finetune.dataset import dataset_builder\n",
    "## 设置随机种子\n",
    "misc.set_random_seed(42)\n",
    "\n",
    "## 读取数据集\n",
    "train_dataloader = dataset_builder(config.dataset.train)\n",
    "val_dataloader = dataset_builder(config.dataset.val)\n",
    "test_dataloader = dataset_builder(config.dataset.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建模型\n",
    "from models.build import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PointTransformer(config.model)\n",
    "model.load_model_from_ckpt(config.ckpt_file)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "model = model.to(device)\n",
    "optimizer, scheduler = build_opti_sche(model, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48520b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 训练\n",
    "start_time = time.time()\n",
    "wandb.init(\n",
    "    project=\"pointmae-finetune\",\n",
    "    config=config,\n",
    "    name=\"age\"\n",
    ")\n",
    "train_loss_array, val_loss_array = train(train_dataloader, val_dataloader, model, optimizer, scheduler, config, device)\n",
    "wandb.finish()  \n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(f\"Total training time: {run_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointmae_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
